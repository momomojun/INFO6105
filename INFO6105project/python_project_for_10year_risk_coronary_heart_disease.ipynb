{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7892340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2927 entries, 0 to 2926\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   age              2927 non-null   int64  \n",
      " 1   education        2927 non-null   int64  \n",
      " 2   sex              2927 non-null   object \n",
      " 3   is_smoking       2927 non-null   object \n",
      " 4   cigsPerDay       2927 non-null   int64  \n",
      " 5   BPMeds           2927 non-null   int64  \n",
      " 6   prevalentStroke  2927 non-null   int64  \n",
      " 7   prevalentHyp     2927 non-null   int64  \n",
      " 8   diabetes         2927 non-null   int64  \n",
      " 9   totChol          2927 non-null   int64  \n",
      " 10  sysBP            2927 non-null   float64\n",
      " 11  diaBP            2927 non-null   float64\n",
      " 12  BMI              2927 non-null   float64\n",
      " 13  heartRate        2927 non-null   int64  \n",
      " 14  glucose          2927 non-null   int64  \n",
      " 15  TenYearCHD       2927 non-null   int64  \n",
      "dtypes: float64(3), int64(11), object(2)\n",
      "memory usage: 366.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Summary:\n",
    "\n",
    "# Developing a semi-supervised learning model on Diabetes dataset \n",
    "# using a super learner and deploying the model on other datasets.\n",
    "\n",
    "# Step 1: Data pre-processing phase\n",
    "\n",
    "# Remove outliers from all columns.\n",
    "# Impute missing values in all columns.\n",
    "# Normalize all columns.\n",
    "\n",
    "# Step 2: Unsupervised Learning for generating labels\n",
    "\n",
    "# Use K-means clustering on three features of Glucose, \n",
    "# BMI and Age to cluster data into two clusters.\n",
    "# Assign ‘Diabetes’ name to the cluster with higher average Glucose \n",
    "# and ‘No Diabetes’ to the other cluster.\n",
    "# Add a new column (Outcome) to the dataset containing 1 for ‘Diabetes’ \n",
    "# and 0 for ‘No Diabetes’. Use these values as labels for classification (step 4).\n",
    "\n",
    "# Step 3: Feature Extraction\n",
    "\n",
    "# Split data into test and training sets (consider 20% for test).\n",
    "# Use PCA on the training data to create 3 new components \n",
    "# from existing features (all columns except outcome).\n",
    "# Transfer training and test data to the new dimensions (PCs).\n",
    "\n",
    "# Step 4: Classification using a super learner\n",
    "\n",
    "# Define three classification models as base classifiers \n",
    "# consisting of Naïve Bayes, Neural Network, and KNN.\n",
    "# Define a decision tree as the meta learner.\n",
    "# Train decision tree (meta learner) on outputs of three base classifiers \n",
    "# using 5-fold cross validation.\n",
    "# Find hyperparameters for all these models which provide the best accuracy rate.\n",
    "# Report accuracy of the model on the test data.\n",
    "\n",
    "# Step 5: Employing the model on other datasets\n",
    "\n",
    "# Use the last column of the assigned dataset as outcome (label).\n",
    "# Use your current code for steps 1,3, and 4 \n",
    "# with minor changes (e.g., encoding categorical variables) \n",
    "# to train your model on the new dataset and calculate the accuracy.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "data = pd.read_csv('Datasets/10year_risk_coronary_heart_disease.csv')\n",
    "# print(data.head(5))\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4564db",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m data_processed \u001b[38;5;241m=\u001b[39m X_new_encoded\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m features_new:\n\u001b[1;32m---> 10\u001b[0m     Q1 \u001b[38;5;241m=\u001b[39m data_processed[col]\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.25\u001b[39m)\n\u001b[0;32m     11\u001b[0m     Q3 \u001b[38;5;241m=\u001b[39m data_processed[col]\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.75\u001b[39m)\n\u001b[0;32m     12\u001b[0m     IQR \u001b[38;5;241m=\u001b[39m Q3 \u001b[38;5;241m-\u001b[39m Q1\n",
      "File \u001b[1;32md:\\pythonWorkplace\\anaconda\\Lib\\site-packages\\pandas\\core\\series.py:2901\u001b[0m, in \u001b[0;36mSeries.quantile\u001b[1;34m(self, q, interpolation)\u001b[0m\n\u001b[0;32m   2897\u001b[0m \u001b[38;5;66;03m# We dispatch to DataFrame so that core.internals only has to worry\u001b[39;00m\n\u001b[0;32m   2898\u001b[0m \u001b[38;5;66;03m#  about 2D cases.\u001b[39;00m\n\u001b[0;32m   2899\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m-> 2901\u001b[0m result \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mquantile(q\u001b[38;5;241m=\u001b[39mq, interpolation\u001b[38;5;241m=\u001b[39minterpolation, numeric_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   2903\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32md:\\pythonWorkplace\\anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:12173\u001b[0m, in \u001b[0;36mDataFrame.quantile\u001b[1;34m(self, q, axis, numeric_only, interpolation, method)\u001b[0m\n\u001b[0;32m  12167\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m  12169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(q):\n\u001b[0;32m  12170\u001b[0m     \u001b[38;5;66;03m# BlockManager.quantile expects listlike, so we wrap and unwrap here\u001b[39;00m\n\u001b[0;32m  12171\u001b[0m     \u001b[38;5;66;03m# error: List item 0 has incompatible type \"float | ExtensionArray |\u001b[39;00m\n\u001b[0;32m  12172\u001b[0m     \u001b[38;5;66;03m# ndarray[Any, Any] | Index | Series | Sequence[float]\"; expected \"float\"\u001b[39;00m\n\u001b[1;32m> 12173\u001b[0m     res_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantile(\n\u001b[0;32m  12174\u001b[0m         [q],  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m  12175\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m  12176\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m  12177\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[0;32m  12178\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m  12179\u001b[0m     )\n\u001b[0;32m  12180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  12181\u001b[0m         res \u001b[38;5;241m=\u001b[39m res_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32md:\\pythonWorkplace\\anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:12218\u001b[0m, in \u001b[0;36mDataFrame.quantile\u001b[1;34m(self, q, axis, numeric_only, interpolation, method)\u001b[0m\n\u001b[0;32m  12214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m  12215\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Method must be in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m  12216\u001b[0m     )\n\u001b[0;32m  12217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m> 12218\u001b[0m     res \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mquantile(qs\u001b[38;5;241m=\u001b[39mq, interpolation\u001b[38;5;241m=\u001b[39minterpolation)\n\u001b[0;32m  12219\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  12220\u001b[0m     valid_interpolation \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigher\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "File \u001b[1;32md:\\pythonWorkplace\\anaconda\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1567\u001b[0m, in \u001b[0;36mBlockManager.quantile\u001b[1;34m(self, qs, interpolation)\u001b[0m\n\u001b[0;32m   1564\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   1565\u001b[0m new_axes[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m Index(qs, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m-> 1567\u001b[0m blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1568\u001b[0m     blk\u001b[38;5;241m.\u001b[39mquantile(qs\u001b[38;5;241m=\u001b[39mqs, interpolation\u001b[38;5;241m=\u001b[39minterpolation) \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m   1569\u001b[0m ]\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(blocks, new_axes)\n",
      "File \u001b[1;32md:\\pythonWorkplace\\anaconda\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1568\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1564\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   1565\u001b[0m new_axes[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m Index(qs, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m   1567\u001b[0m blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m-> 1568\u001b[0m     blk\u001b[38;5;241m.\u001b[39mquantile(qs\u001b[38;5;241m=\u001b[39mqs, interpolation\u001b[38;5;241m=\u001b[39minterpolation) \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m   1569\u001b[0m ]\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(blocks, new_axes)\n",
      "File \u001b[1;32md:\\pythonWorkplace\\anaconda\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1957\u001b[0m, in \u001b[0;36mBlock.quantile\u001b[1;34m(self, qs, interpolation)\u001b[0m\n\u001b[0;32m   1954\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m   1955\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m is_list_like(qs)  \u001b[38;5;66;03m# caller is responsible for this\u001b[39;00m\n\u001b[1;32m-> 1957\u001b[0m result \u001b[38;5;241m=\u001b[39m quantile_compat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, np\u001b[38;5;241m.\u001b[39masarray(qs\u001b[38;5;241m.\u001b[39m_values), interpolation)\n\u001b[0;32m   1958\u001b[0m \u001b[38;5;66;03m# ensure_block_shape needed for cases where we start with EA and result\u001b[39;00m\n\u001b[0;32m   1959\u001b[0m \u001b[38;5;66;03m#  is ndarray, e.g. IntegerArray, SparseArray\u001b[39;00m\n\u001b[0;32m   1960\u001b[0m result \u001b[38;5;241m=\u001b[39m ensure_block_shape(result, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32md:\\pythonWorkplace\\anaconda\\Lib\\site-packages\\pandas\\core\\array_algos\\quantile.py:39\u001b[0m, in \u001b[0;36mquantile_compat\u001b[1;34m(values, qs, interpolation)\u001b[0m\n\u001b[0;32m     37\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m na_value_for_dtype(values\u001b[38;5;241m.\u001b[39mdtype, compat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     38\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m quantile_with_mask(values, mask, fill_value, qs, interpolation)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39m_quantile(qs, interpolation)\n",
      "File \u001b[1;32md:\\pythonWorkplace\\anaconda\\Lib\\site-packages\\pandas\\core\\array_algos\\quantile.py:97\u001b[0m, in \u001b[0;36mquantile_with_mask\u001b[1;34m(values, mask, fill_value, qs, interpolation)\u001b[0m\n\u001b[0;32m     95\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(flat, \u001b[38;5;28mlen\u001b[39m(values))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mlen\u001b[39m(values), \u001b[38;5;28mlen\u001b[39m(qs))\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 97\u001b[0m     result \u001b[38;5;241m=\u001b[39m _nanpercentile(\n\u001b[0;32m     98\u001b[0m         values,\n\u001b[0;32m     99\u001b[0m         qs \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100.0\u001b[39m,\n\u001b[0;32m    100\u001b[0m         na_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    101\u001b[0m         mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    102\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[0;32m    103\u001b[0m     )\n\u001b[0;32m    105\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result)\n\u001b[0;32m    106\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32md:\\pythonWorkplace\\anaconda\\Lib\\site-packages\\pandas\\core\\array_algos\\quantile.py:218\u001b[0m, in \u001b[0;36m_nanpercentile\u001b[1;34m(values, qs, na_value, mask, interpolation)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mpercentile(\n\u001b[0;32m    219\u001b[0m         values,\n\u001b[0;32m    220\u001b[0m         qs,\n\u001b[0;32m    221\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;66;03m# error: No overload variant of \"percentile\" matches argument types\u001b[39;00m\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;66;03m# \"ndarray[Any, Any]\", \"ndarray[Any, dtype[floating[_64Bit]]]\",\u001b[39;00m\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;66;03m# \"int\", \"Dict[str, str]\"  [call-overload]\u001b[39;00m\n\u001b[0;32m    225\u001b[0m         method\u001b[38;5;241m=\u001b[39minterpolation,  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32md:\\pythonWorkplace\\anaconda\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4292\u001b[0m, in \u001b[0;36mpercentile\u001b[1;34m(a, q, axis, out, overwrite_input, method, keepdims, weights, interpolation)\u001b[0m\n\u001b[0;32m   4289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(weights \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   4290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights must be non-negative.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 4292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _quantile_unchecked(\n\u001b[0;32m   4293\u001b[0m     a, q, axis, out, overwrite_input, method, keepdims, weights)\n",
      "File \u001b[1;32md:\\pythonWorkplace\\anaconda\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4569\u001b[0m, in \u001b[0;36m_quantile_unchecked\u001b[1;34m(a, q, axis, out, overwrite_input, method, keepdims, weights)\u001b[0m\n\u001b[0;32m   4560\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_quantile_unchecked\u001b[39m(a,\n\u001b[0;32m   4561\u001b[0m                         q,\n\u001b[0;32m   4562\u001b[0m                         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4566\u001b[0m                         keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   4567\u001b[0m                         weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   4568\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ureduce(a,\n\u001b[0;32m   4570\u001b[0m                     func\u001b[38;5;241m=\u001b[39m_quantile_ureduce_func,\n\u001b[0;32m   4571\u001b[0m                     q\u001b[38;5;241m=\u001b[39mq,\n\u001b[0;32m   4572\u001b[0m                     weights\u001b[38;5;241m=\u001b[39mweights,\n\u001b[0;32m   4573\u001b[0m                     keepdims\u001b[38;5;241m=\u001b[39mkeepdims,\n\u001b[0;32m   4574\u001b[0m                     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   4575\u001b[0m                     out\u001b[38;5;241m=\u001b[39mout,\n\u001b[0;32m   4576\u001b[0m                     overwrite_input\u001b[38;5;241m=\u001b[39moverwrite_input,\n\u001b[0;32m   4577\u001b[0m                     method\u001b[38;5;241m=\u001b[39mmethod)\n",
      "File \u001b[1;32md:\\pythonWorkplace\\anaconda\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3914\u001b[0m, in \u001b[0;36m_ureduce\u001b[1;34m(a, func, keepdims, **kwargs)\u001b[0m\n\u001b[0;32m   3911\u001b[0m     index_out \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, ) \u001b[38;5;241m*\u001b[39m nd\n\u001b[0;32m   3912\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out[(\u001b[38;5;28mEllipsis\u001b[39m, ) \u001b[38;5;241m+\u001b[39m index_out]\n\u001b[1;32m-> 3914\u001b[0m r \u001b[38;5;241m=\u001b[39m func(a, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32md:\\pythonWorkplace\\anaconda\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4744\u001b[0m, in \u001b[0;36m_quantile_ureduce_func\u001b[1;34m(a, q, weights, axis, out, overwrite_input, method)\u001b[0m\n\u001b[0;32m   4742\u001b[0m     arr \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m   4743\u001b[0m     wgt \u001b[38;5;241m=\u001b[39m weights\n\u001b[1;32m-> 4744\u001b[0m result \u001b[38;5;241m=\u001b[39m _quantile(arr,\n\u001b[0;32m   4745\u001b[0m                    quantiles\u001b[38;5;241m=\u001b[39mq,\n\u001b[0;32m   4746\u001b[0m                    axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   4747\u001b[0m                    method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   4748\u001b[0m                    out\u001b[38;5;241m=\u001b[39mout,\n\u001b[0;32m   4749\u001b[0m                    weights\u001b[38;5;241m=\u001b[39mwgt)\n\u001b[0;32m   4750\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\pythonWorkplace\\anaconda\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4876\u001b[0m, in \u001b[0;36m_quantile\u001b[1;34m(arr, quantiles, axis, method, out, weights)\u001b[0m\n\u001b[0;32m   4874\u001b[0m         result_shape \u001b[38;5;241m=\u001b[39m virtual_indexes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m*\u001b[39m (arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   4875\u001b[0m         gamma \u001b[38;5;241m=\u001b[39m gamma\u001b[38;5;241m.\u001b[39mreshape(result_shape)\n\u001b[1;32m-> 4876\u001b[0m         result \u001b[38;5;241m=\u001b[39m _lerp(previous,\n\u001b[0;32m   4877\u001b[0m                     \u001b[38;5;28mnext\u001b[39m,\n\u001b[0;32m   4878\u001b[0m                     gamma,\n\u001b[0;32m   4879\u001b[0m                     out\u001b[38;5;241m=\u001b[39mout)\n\u001b[0;32m   4880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4881\u001b[0m     \u001b[38;5;66;03m# Weighted case\u001b[39;00m\n\u001b[0;32m   4882\u001b[0m     \u001b[38;5;66;03m# This implements method=\"inverted_cdf\", the only supported weighted\u001b[39;00m\n\u001b[0;32m   4883\u001b[0m     \u001b[38;5;66;03m# method, which needs to sort anyway.\u001b[39;00m\n\u001b[0;32m   4884\u001b[0m     weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(weights)\n",
      "File \u001b[1;32md:\\pythonWorkplace\\anaconda\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4671\u001b[0m, in \u001b[0;36m_lerp\u001b[1;34m(a, b, t, out)\u001b[0m\n\u001b[0;32m   4657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_lerp\u001b[39m(a, b, t, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   4658\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4659\u001b[0m \u001b[38;5;124;03m    Compute the linear interpolation weighted by gamma on each point of\u001b[39;00m\n\u001b[0;32m   4660\u001b[0m \u001b[38;5;124;03m    two same shape array.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4669\u001b[0m \u001b[38;5;124;03m        Output array.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4671\u001b[0m     diff_b_a \u001b[38;5;241m=\u001b[39m subtract(b, a)\n\u001b[0;32m   4672\u001b[0m     \u001b[38;5;66;03m# asanyarray is a stop-gap until gh-13105\u001b[39;00m\n\u001b[0;32m   4673\u001b[0m     lerp_interpolation \u001b[38;5;241m=\u001b[39m asanyarray(add(a, diff_b_a \u001b[38;5;241m*\u001b[39m t, out\u001b[38;5;241m=\u001b[39mout))\n",
      "\u001b[1;31mTypeError\u001b[0m: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead."
     ]
    }
   ],
   "source": [
    "#pre processing\n",
    "target = 'TenYearCHD'\n",
    "y_new = data[target]\n",
    "X_new = data.drop(columns=[target])\n",
    "categorical_features = ['sex', 'is_smoking']\n",
    "X_new_encoded = pd.get_dummies(X_new, columns=categorical_features, drop_first=True)\n",
    "\n",
    "categorical_features_encoded = ['sex_M', 'is_smoking_YES']\n",
    "continuous_features = [\n",
    "    col for col in X_new_encoded.columns \n",
    "    if col not in categorical_features_encoded\n",
    "]\n",
    "data_processed = X_new_encoded.copy()\n",
    "\n",
    "for col in continuous_features:\n",
    "    Q1 = data_processed[col].quantile(0.25)\n",
    "    Q3 = data_processed[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - (1.5 * IQR)\n",
    "    upper_bound = Q3 + (1.5 * IQR)\n",
    "    data_processed.loc[\n",
    "        (data_processed[col] < lower_bound) | \n",
    "        (data_processed[col] > upper_bound),\n",
    "        col\n",
    "    ] = np.nan\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "data_processed[continuous_features] = imputer.fit_transform(data_processed[continuous_features])\n",
    "print(data_processed[continuous_features].isnull().sum().head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fa15b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Feature Extraction\n",
    "\n",
    "# Split data into test and training sets (consider 20% for test).\n",
    "# Use PCA on the training data to create 3 new components \n",
    "# from existing features (all columns except outcome).\n",
    "# Transfer training and test data to the new dimensions (PCs).\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_processed, y_new, test_size=0.2, random_state=42)\n",
    "PCA_scaler = StandardScaler()\n",
    "X_train_scaled = PCA_scaler.fit_transform(X_train)\n",
    "X_test_scaled = PCA_scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed47ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Classification using a super learner\n",
    "\n",
    "# Define three classification models as base classifiers \n",
    "# consisting of Naïve Bayes, Neural Network, and KNN.\n",
    "# Define a decision tree as the meta learner.\n",
    "# Train decision tree (meta learner) on outputs of three base classifiers \n",
    "# using 5-fold cross validation.\n",
    "# Find hyperparameters for all these models which provide the best accuracy rate.\n",
    "# Report accuracy of the model on the test data.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# create instance for three classification models\n",
    "base_nb = GaussianNB()\n",
    "base_nn = MLPClassifier(max_iter=1000, random_state=42)\n",
    "base_knn = KNeighborsClassifier()\n",
    "# create the meta learner\n",
    "meta_learner = DecisionTreeClassifier(random_state=42)\n",
    "level0_estimators = [\n",
    "    ('nb', base_nb),\n",
    "    ('nn', base_nn),\n",
    "    ('knn', base_knn)\n",
    "]\n",
    "#create super learner using 5-fold cross validation\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=level0_estimators,\n",
    "    final_estimator=meta_learner,\n",
    "    cv = 5\n",
    ")\n",
    "smote_pipeline = ImbPipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('superlearner', stacking_model) \n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    # try more hyperparemeters\n",
    "    'knn__n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "\n",
    "    # try more layer sizes and learning rate\n",
    "    'nn__hidden_layer_sizes': [(25,), (50,), (100,), (25, 25)],\n",
    "    'nn__alpha': [0.0001, 0.001, 0.01],\n",
    "\n",
    "    # try more hyperparemeters\n",
    "    'final_estimator__max_depth': [3, 5, 7, 10],\n",
    "    'final_estimator__min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "# create SMOTE param_grid\n",
    "smote_param_grid = {}\n",
    "for key, value in param_grid.items():\n",
    "    smote_param_grid[f'superlearner__{key}'] = value\n",
    "\n",
    "# change GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=smote_pipeline,      # use SMOTE Pipeline\n",
    "    param_grid=smote_param_grid,   # use SMOTE grid\n",
    "    cv=5, \n",
    "    scoring='f1_macro',            # don't use 'accuracy', use F1-score\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "\n",
    "print(f\"best hyperparameters: \\n{grid_search.best_params_}\")\n",
    "y_pred_test = grid_search.predict(X_test_pca)\n",
    "final_report = classification_report(y_test, y_pred_test)\n",
    "print(\"\\nClassification Report (SMOTE):\")\n",
    "print(final_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
